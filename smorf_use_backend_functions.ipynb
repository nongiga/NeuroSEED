{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyPzAuvycefH"
   },
   "source": [
    "Install and import the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym4wkXPfc4O3",
    "outputId": "6285cb49-5a92-4fb1-a8c7-f5acf731abf1"
   },
   "outputs": [],
   "source": [
    "os.environ['GEOMSTATS_BACKEND'] = 'pytorch'\n",
    "import torch\n",
    "import os \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from util.data_handling.data_loader import get_dataloaders\n",
    "from edit_distance.train import load_edit_distance_dataset,train,test\n",
    "from edit_distance.models.pair_encoder import PairEmbeddingDistance\n",
    "from edit_distance.models.linear_encoder import LinearEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0EAvdHOjOoU"
   },
   "source": [
    "In this notebook, we only show the code to run a simple linear layer on the sequence which, in the hyperbolic space, already gives particularly good results. Later we will also report results for more complex models whose implementation can be found in the [NeuroSEED repository](https://github.com/gcorso/NeuroSEED)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDa6aholkv4z"
   },
   "source": [
    "General training and evaluation routines used to train the models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49GU1jZAlBTE"
   },
   "source": [
    "The linear model is trained on 7000 sequences (+700 of validation) and tested on 1500 different sequences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noga/NeuroSEED/neuroseed/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperbolic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(2021)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(2021)\n",
    "\n",
    "# load data\n",
    "datasets = load_edit_distance_dataset('./datasets/string_for_test.pkl')\n",
    "loaders = get_dataloaders(datasets, batch_size=128, workers=5)\n",
    "\n",
    "# model, optimizer and loss\n",
    "model,optimizer,loss,loss_train,loss_val,avg_loss={},{},{},{},{},{}\n",
    "\n",
    "encoder = LinearEncoder(153, EMBEDDING_SIZE)\n",
    "\n",
    "dist_types=['hyperbolic','euclidean']\n",
    "\n",
    "from util.ml_and_math.loss_functions import AverageMeter\n",
    "\n",
    "    \n",
    "for dt in dist_types:\n",
    "    print(dt)\n",
    "\n",
    "    model[dt] = PairEmbeddingDistance(embedding_model=encoder, distance=dt)\n",
    "    loss[dt] = nn.MSELoss()\n",
    "\n",
    "    optimizer[dt] = optim.Adam(model[dt].parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    # training\n",
    "    for epoch in range(0, 1):\n",
    "        t = time.time()\n",
    "        loss_train[dt] = train(model[dt], loaders['train'], optimizer[dt], loss[dt], device)\n",
    "        loss_val[dt] = test(model[dt], loaders['val'], loss[dt], device)\n",
    "\n",
    "        # print progress\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch: {:02d}'.format(epoch),\n",
    "                'loss_train: {:.6f}'.format(loss_train[dt]),\n",
    "                'loss_val: {:.6f}'.format(loss_val[dt]),\n",
    "                'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "    # testing\n",
    "    for dset in loaders.keys():\n",
    "        avg_loss = test(model[dt], loaders[dset], loss, device)\n",
    "        print('Final results {}: loss = {:.6f}'.format(dset, avg_loss))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural SEED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
