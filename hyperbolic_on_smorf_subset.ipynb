{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyPzAuvycefH"
   },
   "source": [
    "Install and import the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FwCBrVVic4Xp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geoopt==0.3.1 in ./neuroseed/lib/python3.8/site-packages (0.3.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in ./neuroseed/lib/python3.8/site-packages (from geoopt==0.3.1) (1.7.1+cu101)\n",
      "Requirement already satisfied: numpy in ./neuroseed/lib/python3.8/site-packages (from geoopt==0.3.1) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in ./neuroseed/lib/python3.8/site-packages (from torch>=1.4.0->geoopt==0.3.1) (4.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/noga/NeuroSEED/neuroseed/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu101 in ./neuroseed/lib/python3.8/site-packages (1.7.1+cu101)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu101 in ./neuroseed/lib/python3.8/site-packages (0.8.2+cu101)\n",
      "Requirement already satisfied: torchaudio==0.7.2 in ./neuroseed/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy in ./neuroseed/lib/python3.8/site-packages (from torch==1.7.1+cu101) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in ./neuroseed/lib/python3.8/site-packages (from torch==1.7.1+cu101) (4.1.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in ./neuroseed/lib/python3.8/site-packages (from torchvision==0.8.2+cu101) (9.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/noga/NeuroSEED/neuroseed/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: geomstats==2.2 in ./neuroseed/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.22.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (3.5.1)\n",
      "Requirement already satisfied: joblib==0.14.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.8.0)\n",
      "Requirement already satisfied: autograd==1.3 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.3)\n",
      "Requirement already satisfied: jupyter in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.0.0)\n",
      "Requirement already satisfied: future>=0.15.2 in ./neuroseed/lib/python3.8/site-packages (from autograd==1.3->geomstats==2.2) (0.18.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./neuroseed/lib/python3.8/site-packages (from scikit-learn>=0.22.1->geomstats==2.2) (3.1.0)\n",
      "Requirement already satisfied: qtconsole in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (5.2.2)\n",
      "Requirement already satisfied: ipykernel in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.9.1)\n",
      "Requirement already satisfied: notebook in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.4.8)\n",
      "Requirement already satisfied: jupyter-console in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.4.3)\n",
      "Requirement already satisfied: nbconvert in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.4.2)\n",
      "Requirement already satisfied: ipywidgets in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (7.6.5)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (0.1.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (8.1.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (7.1.2)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (5.1.1)\n",
      "Requirement already satisfied: nest-asyncio in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (1.5.4)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (1.5.1)\n",
      "Requirement already satisfied: pickleshare in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.7.5)\n",
      "Requirement already satisfied: stack-data in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (4.8.0)\n",
      "Requirement already satisfied: decorator in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (2.11.2)\n",
      "Requirement already satisfied: backcall in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (56.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (3.0.28)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./neuroseed/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (4.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (0.4)\n",
      "Requirement already satisfied: pyzmq>=13 in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (22.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./neuroseed/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./neuroseed/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./neuroseed/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (1.16.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (5.2.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (1.0.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./neuroseed/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./neuroseed/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (21.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in ./neuroseed/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./neuroseed/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (0.18.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./neuroseed/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (3.7.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (0.13.3)\n",
      "Requirement already satisfied: jinja2 in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (3.0.3)\n",
      "Requirement already satisfied: prometheus-client in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./neuroseed/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->geomstats==2.2) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./neuroseed/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->geomstats==2.2) (1.15.0)\n",
      "Requirement already satisfied: pycparser in ./neuroseed/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->geomstats==2.2) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./neuroseed/lib/python3.8/site-packages (from jinja2->notebook->jupyter->geomstats==2.2) (2.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (4.30.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (1.3.2)\n",
      "Requirement already satisfied: bleach in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.5.12)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.1.2)\n",
      "Requirement already satisfied: testpath in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.8.4)\n",
      "Requirement already satisfied: webencodings in ./neuroseed/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->geomstats==2.2) (0.5.1)\n",
      "Requirement already satisfied: qtpy in ./neuroseed/lib/python3.8/site-packages (from qtconsole->jupyter->geomstats==2.2) (2.0.1)\n",
      "Requirement already satisfied: pure-eval in ./neuroseed/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.2)\n",
      "Requirement already satisfied: executing in ./neuroseed/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.8.3)\n",
      "Requirement already satisfied: asttokens in ./neuroseed/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (2.0.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/noga/NeuroSEED/neuroseed/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install geoopt==0.3.1\n",
    "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip3 install geomstats==2.2\n",
    "os.environ['GEOMSTATS_BACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym4wkXPfc4O3",
    "outputId": "6285cb49-5a92-4fb1-a8c7-f5acf731abf1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from geomstats.geometry.poincare_ball import PoincareBall\n",
    "\n",
    "from edit_distance.train import load_edit_distance_dataset\n",
    "from util.data_handling.data_loader import get_dataloaders\n",
    "from util.ml_and_math.loss_functions import AverageMeter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0EAvdHOjOoU"
   },
   "source": [
    "In this notebook, we only show the code to run a simple linear layer on the sequence which, in the hyperbolic space, already gives particularly good results. Later we will also report results for more complex models whose implementation can be found in the [NeuroSEED repository](https://github.com/gcorso/NeuroSEED)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EXBg45KBeACe"
   },
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\n",
    "    \"\"\"  Linear model which simply flattens the sequence and applies a linear transformation. \"\"\"\n",
    "\n",
    "    def __init__(self, len_sequence, embedding_size, alphabet_size=4):\n",
    "        super(LinearEncoder, self).__init__()\n",
    "        self.encoder = nn.Linear(in_features=alphabet_size * len_sequence, \n",
    "                                 out_features=embedding_size)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # flatten sequence and apply layer\n",
    "        B = sequence.shape[0]\n",
    "        sequence = sequence.reshape(B, -1)\n",
    "        emb = self.encoder(sequence)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class PairEmbeddingDistance(nn.Module):\n",
    "    \"\"\" Wrapper model for a general encoder, computes pairwise distances and applies projections \"\"\"\n",
    "\n",
    "    def hyperbolic_metric(self, enc_sequence):\n",
    "        distance=PoincareBall(self.embedding_size).metric.dist(enc_sequence[:, 0], enc_sequence[:, 1])\n",
    "        distance = distance * self.scaling\n",
    "        return distance\n",
    "\n",
    "    def euclidean_metric(self, enc_sequence):\n",
    "        distance=torch.norm(enc_sequence[:, 0]-enc_sequence[:, 1], dim=-1)\n",
    "        return distance\n",
    "\n",
    "    def __init__(self, embedding_model, embedding_size, scaling=False,hyperbolic=True):\n",
    "        super(PairEmbeddingDistance, self).__init__()\n",
    "\n",
    "        self.embedding_size=embedding_size\n",
    "\n",
    "        if hyperbolic:\n",
    "            self.metric = self.hyperbolic_metric\n",
    "            self.radius = nn.Parameter(torch.Tensor([1e-2]), requires_grad=True)\n",
    "            self.scaling = nn.Parameter(torch.Tensor([1.]), requires_grad=True)\n",
    "        else:\n",
    "            self.metric=self.euclidean_metric\n",
    "\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "\n",
    "\n",
    "    def normalize_embeddings(self, embeddings):\n",
    "        \"\"\" Project embeddings to an hypersphere of a certain radius \"\"\"\n",
    "        if self.hyperbolic_metric==True:\n",
    "            min_scale = 1e-7\n",
    "            max_scale = 1 - 1e-3\n",
    "            return F.normalize(embeddings, p=2, dim=1) * self.radius.clamp_min(min_scale).clamp_max(max_scale)\n",
    "        else:\n",
    "            return embeddings\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        \"\"\" Use embedding model and normalization to encode some sequences. \"\"\"\n",
    "        enc_sequence = self.embedding_model(sequence)\n",
    "        enc_sequence = self.normalize_embeddings(enc_sequence)\n",
    "        return enc_sequence\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # flatten couples\n",
    "        (B, _, N, _) = sequence.shape\n",
    "        sequence = sequence.reshape(2 * B, N, -1)\n",
    "\n",
    "        # encode sequences\n",
    "        enc_sequence = self.encode(sequence)\n",
    "\n",
    "        # compute distances\n",
    "        enc_sequence = enc_sequence.reshape(B, 2, -1)\n",
    "\n",
    "        distance = self.metric(enc_sequence)\n",
    "\n",
    "\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDa6aholkv4z"
   },
   "source": [
    "General training and evaluation routines used to train the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0_TS2a5VmQCQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, loader, optimizer, loss, device):\n",
    "    avg_loss = AverageMeter()\n",
    "    model.train()\n",
    "\n",
    "    for sequences, labels in loader:\n",
    "        # move examples to right device\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        optimizer.zero_grad()\n",
    "        output = model(sequences)\n",
    "\n",
    "        # loss and backpropagation\n",
    "        loss_train = loss(output, labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of average loss\n",
    "        avg_loss.update(loss_train.data.item(), sequences.shape[0])\n",
    "\n",
    "    return avg_loss.avg\n",
    "\n",
    "\n",
    "def test(model, loader, loss, device):\n",
    "    avg_loss = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    for sequences, labels in loader:\n",
    "        # move examples to right device\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "        # forward propagation and loss computation\n",
    "        output = model(sequences)\n",
    "        loss_val = loss(output, labels).data.item()\n",
    "        avg_loss.update(loss_val, sequences.shape[0])\n",
    "\n",
    "    return avg_loss.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49GU1jZAlBTE"
   },
   "source": [
    "The linear model is trained on 7000 sequences (+700 of validation) and tested on 1500 different sequences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test'])\n"
     ]
    }
   ],
   "source": [
    "# create subset of qiita to better understand mechanisms\n",
    "import pickle\n",
    "\n",
    "with open('./datasets/string_subset.pkl', 'rb') as f:\n",
    "        sequences, distances = pickle.load(f)\n",
    "\n",
    "print(distances.keys())\n",
    "slices={'train':7000, 'test':700, 'val':1500}\n",
    "smaller_distances = {key: distances[key][:slices[key],:slices[key]] for key in distances.keys()}\n",
    "smaller_sequences = {key: sequences[key][:slices[key]] for key in sequences.keys()}\n",
    "\n",
    "pickle.dump((smaller_sequences, smaller_distances),open('./datasets/string_subsubset' + \".pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 loss_train: 924.024585 loss_val: 836.552754 time: 1.6643s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000009vscode-remote?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m20\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000009vscode-remote?line=25'>26</a>\u001b[0m     t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000009vscode-remote?line=26'>27</a>\u001b[0m     loss_train \u001b[39m=\u001b[39m train(model[\u001b[39m'\u001b[39;49m\u001b[39mhyperbolic\u001b[39;49m\u001b[39m'\u001b[39;49m], loaders[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], optimizer, loss, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000009vscode-remote?line=27'>28</a>\u001b[0m     loss_val[\u001b[39m'\u001b[39m\u001b[39mhyperbolic\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test(model[\u001b[39m'\u001b[39m\u001b[39mhyperbolic\u001b[39m\u001b[39m'\u001b[39m], loaders[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m], loss, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000009vscode-remote?line=29'>30</a>\u001b[0m     \u001b[39m# print progress\u001b[39;00m\n",
      "\u001b[1;32m/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb Cell 7'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, loss, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000006vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, loader, optimizer, loss, device):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000006vscode-remote?line=1'>2</a>\u001b[0m     avg_loss \u001b[39m=\u001b[39m AverageMeter()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m sequences, labels \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m         \u001b[39m# move examples to right device\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baeolus/home/noga/NeuroSEED/hyperbolic_on_smorf_subset.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m         sequences, labels \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "from edit_distance.train import load_edit_distance_dataset\n",
    "\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(2021)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(2021)\n",
    "\n",
    "# load data\n",
    "datasets = load_edit_distance_dataset('./datasets/string_for_test.pkl')\n",
    "loaders = get_dataloaders(datasets, batch_size=128, workers=5)\n",
    "\n",
    "# model, optimizer and loss\n",
    "model=optimizer=loss=loss_train=loss_val=avg_loss={}\n",
    "\n",
    "encoder = LinearEncoder(153, EMBEDDING_SIZE)\n",
    "model['hyperbolic'] = PairEmbeddingDistance(embedding_model=encoder, embedding_size=EMBEDDING_SIZE)\n",
    "model['hyperbolic'].to(device)\n",
    "\n",
    "optimizer = optim.Adam(model['hyperbolic'].parameters(), lr=0.001)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# training\n",
    "for epoch in range(0, 20):\n",
    "    t = time.time()\n",
    "    loss_train = train(model['hyperbolic'], loaders['train'], optimizer, loss, device)\n",
    "    loss_val['hyperbolic'] = test(model['hyperbolic'], loaders['val'], loss, device)\n",
    "\n",
    "    # print progress\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch: {:02d}'.format(epoch),\n",
    "              'loss_train: {:.6f}'.format(loss_train),\n",
    "              'loss_val: {:.6f}'.format(loss_val['hyperbolic']),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "      \n",
    "# testing\n",
    "for dset in loaders.keys():\n",
    "    avg_loss = test(model['hyperbolic'], loaders[dset], loss, device)\n",
    "    print('Final results {}: loss = {:.6f}'.format(dset, avg_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 loss_train: 0.103979 loss_val: 0.001626 time: 414.7923s\n",
      "Epoch: 01 loss_train: 0.001360 loss_val: 0.001742 time: 415.0668s\n",
      "Epoch: 02 loss_train: 0.001722 loss_val: 0.002383 time: 414.3412s\n",
      "Epoch: 03 loss_train: 0.002209 loss_val: 0.002347 time: 414.1662s\n",
      "Epoch: 04 loss_train: 0.002588 loss_val: 0.002653 time: 413.1137s\n",
      "Final results train: loss = 0.002938\n",
      "Final results val: loss = 0.002653\n",
      "Final results test: loss = 0.002803\n"
     ]
    }
   ],
   "source": [
    "from edit_distance.train import load_edit_distance_dataset_calculate\n",
    "\n",
    "# model, optimizer and loss\n",
    "model['euclidean'] = PairEmbeddingDistance(embedding_model=encoder, embedding_size=EMBEDDING_SIZE, hyperbolic=False)\n",
    "model['euclidean'].to(device)\n",
    "\n",
    "optimizer = optim.Adam(model['euclidean'].parameters(), lr=0.001)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# training\n",
    "for epoch in range(0, 5):\n",
    "    t = time.time()\n",
    "    loss_train = train(model['euclidean'], loaders['train'], optimizer, loss, device)\n",
    "    loss_val = test(model['euclidean'], loaders['val'], loss, device)\n",
    "\n",
    "    # print progress\n",
    "    if epoch % 1 == 0:\n",
    "        print('Epoch: {:02d}'.format(epoch),\n",
    "              'loss_train: {:.6f}'.format(loss_train),\n",
    "              'loss_val: {:.6f}'.format(loss_val),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "      \n",
    "# testing\n",
    "for dset in loaders.keys():\n",
    "    avg_loss = test(model['euclidean'], loaders[dset], loss, device)\n",
    "    print('Final results {}: loss = {:.6f}'.format(dset, avg_loss))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural SEED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
