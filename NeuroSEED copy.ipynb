{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuMJWX_7SgIB"
   },
   "source": [
    "# Neural Sequence Distance Embeddings\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gcorso/NeuroSEED/blob/master/tutorial/NeuroSEED.ipynb)\n",
    "\n",
    "The improvement of data-dependent heuristics and representation for biological sequences is a critical requirement to fully exploit the recent technological and scientific advancements for human microbiome analysis. This notebook presents Neural Sequence Distance Embeddings (NeuroSEED), a novel framework to embed biological sequences in geometric vector spaces that unifies recently proposed approaches. We demonstrate its capacity by presenting different ways it can be applied to the tasks of edit distance approximation, closest string retrieval, hierarchical clustering and multiple sequence alignment. In particular, the hyperbolic space is shown to be a key component to embed biological sequences and obtain competitive heuristics. Benchmarked with common bioinformatics and machine learning baselines, the proposed approaches display significant accuracy and/or runtime improvements on real-world datasets formed by sequences from samples of the human microbiome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNWhBfRtV0wm"
   },
   "source": [
    "![Cover](https://raw.githubusercontent.com/gcorso/NeuroSEED/master/tutorial/cover.png)\n",
    "\n",
    "Figure 1: On the left, a diagram of the NeuroSEED underlying idea: embed sequences in vector spaces preserving the edit distance between them and then extract information from the vector space. On the right, an example of the hierarchical clustering produced on the PoincarÃ¨ disk from the P53 tumour protein from 20 different organisms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIht2F8eUsec"
   },
   "source": [
    "## Introduction and Motivation\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Dysfunctions of the human microbiome (Morgan & Huttenhower, 2012) have been linked to many serious diseases ranging from diabetes and antibiotic resistance to inflammatory bowel disease. Its usage as a biomarker for the diagnosis and as a target for interventions is a very active area of research. Thanks to the advances in sequencing technologies, modern analysis relies on sequence reads that can be generated relatively quickly. However, to fully exploit the potential of these advances for personalised medicine, the computational methods used in the analysis have to significantly improve in terms of speed and accuracy.\n",
    "\n",
    "![Classical microbiome analysis](https://raw.githubusercontent.com/gcorso/NeuroSEED/master/tutorial/microbiome_analysis.png)\n",
    "\n",
    "Figure 2: Traditional approach to the analysis of the 16S rRNA sequences from the microbiome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtYgkAgYUx3p"
   },
   "source": [
    "### Problem\n",
    "\n",
    "While the number of available biological sequences has been growing exponentially over the past decades, most of the problems related to string matching have not been addressed by the recent advances in machine learning. Classical algorithms are data-independent and, therefore, cannot exploit the low-dimensional manifold assumption that characterises real-world data. Exploiting the available data to produce data-dependent heuristics and representations would greatly accelerate large-scale analyses that are critical to microbiome analysis and other biological research. \n",
    "\n",
    "Unlike most tasks in computer vision and NLP, string matching problems are typically formulated as combinatorial optimisation problems. These discrete formulations do not fit well with the current deep learning approaches causing these problems to be left mostly unexplored by the community. Current supervised learning methods also suffer from the lack of labels that characterises many downstream applications with biological sequences. On the other hand, common self-supervised learning approaches, very successful in NLP, are less effective in the biological context where relations tend to be per-sequence rather than per-token (McDermott et al. 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xztLd6M_ZpKn"
   },
   "source": [
    "\n",
    "### Neural Sequence Distance Embedding\n",
    "\n",
    "In this notebook, we present Neural Sequence Distance Embeddings (NeuroSEED), a general framework to produce representations for biological sequences where the distance in the embedding space is correlated with the evolutionary distance between sequences. This control over the geometric interpretation of the representation space enables the use of geometrical data processing tools for the analysis of the spectrum of sequences.\n",
    "\n",
    "![Classical microbiome analysis](https://raw.githubusercontent.com/gcorso/NeuroSEED/master/tutorial/edit_diagram.PNG)\n",
    "\n",
    "Figure 3: The key idea of NeuroSEED is to learn an encoder function that preserves distances between the sequence and vector space.\n",
    "\n",
    "\n",
    "Examining the task of embedding sequences to preserve the edit distance reveals the importance of data-dependent approaches and of using a geometry that matches well the underlying distribution in the data analysed. For biological datasets, that have an implicit hierarchical structure given by evolution, the hyperbolic space provides significant improvement.\n",
    "\n",
    "We show the potential of the framework by analysing three fundamental tasks in bioinformatics: closest string retrieval, hierarchical clustering and multiple sequence alignment. For all tasks, relatively simple unsupervised approaches using NeuroSEED encoders significantly outperform data-independent heuristics in terms of accuracy and/or runtime. In the paper (preprint will be available soon) and the [complete repository](https://github.com/gcorso/NeuroSEED) we also present more complex geometrical approaches to hierarchical clustering and multiple sequence alignment.\n",
    "\n",
    "\n",
    "## 2. Analysis\n",
    "\n",
    "To improve readability and limit the size of the notebook we make use of some subroutines in the [official repository](https://github.com/gcorso/NeuroSEED) for the research project. The code in the notebook is our best effort to convey the promising application of hyperbolic geometry to this novel research direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyPzAuvycefH"
   },
   "source": [
    "Install and import the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FwCBrVVic4Xp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geoopt==0.3.1 in ./neuroseed/lib/python3.8/site-packages (0.3.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in ./neuroseed/lib/python3.8/site-packages (from geoopt==0.3.1) (1.7.1+cu101)\n",
      "Requirement already satisfied: numpy in ./neuroseed/lib/python3.8/site-packages (from geoopt==0.3.1) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in ./neuroseed/lib/python3.8/site-packages (from torch>=1.4.0->geoopt==0.3.1) (4.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/noga/NeuroSEED/neuroseed/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu101 in ./neuroseed/lib/python3.8/site-packages (1.7.1+cu101)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu101 in ./neuroseed/lib/python3.8/site-packages (0.8.2+cu101)\n",
      "Requirement already satisfied: torchaudio==0.7.2 in ./neuroseed/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy in ./neuroseed/lib/python3.8/site-packages (from torch==1.7.1+cu101) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in ./neuroseed/lib/python3.8/site-packages (from torch==1.7.1+cu101) (4.1.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in ./neuroseed/lib/python3.8/site-packages (from torchvision==0.8.2+cu101) (9.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/noga/NeuroSEED/neuroseed/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: geomstats==2.2 in ./neuroseed/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.8.0)\n",
      "Requirement already satisfied: jupyter in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.0.0)\n",
      "Requirement already satisfied: autograd==1.3 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.3)\n",
      "Requirement already satisfied: joblib==0.14.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in ./neuroseed/lib/python3.8/site-packages (from geomstats==2.2) (3.5.1)\n",
      "Requirement already satisfied: future>=0.15.2 in ./neuroseed/lib/python3.8/site-packages (from autograd==1.3->geomstats==2.2) (0.18.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./neuroseed/lib/python3.8/site-packages (from scikit-learn>=0.22.1->geomstats==2.2) (3.1.0)\n",
      "Requirement already satisfied: qtconsole in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (5.2.2)\n",
      "Requirement already satisfied: jupyter-console in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.4.3)\n",
      "Requirement already satisfied: ipywidgets in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (7.6.5)\n",
      "Requirement already satisfied: ipykernel in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.9.1)\n",
      "Requirement already satisfied: notebook in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.4.8)\n",
      "Requirement already satisfied: nbconvert in ./neuroseed/lib/python3.8/site-packages (from jupyter->geomstats==2.2) (6.4.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (7.1.2)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (8.1.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (1.5.1)\n",
      "Requirement already satisfied: nest-asyncio in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (1.5.4)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (0.1.3)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in ./neuroseed/lib/python3.8/site-packages (from ipykernel->jupyter->geomstats==2.2) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.7.5)\n",
      "Requirement already satisfied: stack-data in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (56.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (4.8.0)\n",
      "Requirement already satisfied: backcall in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./neuroseed/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (3.0.28)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./neuroseed/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (4.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (0.4)\n",
      "Requirement already satisfied: pyzmq>=13 in ./neuroseed/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (22.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./neuroseed/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./neuroseed/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./neuroseed/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel->jupyter->geomstats==2.2) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (5.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./neuroseed/lib/python3.8/site-packages (from ipywidgets->jupyter->geomstats==2.2) (3.5.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./neuroseed/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./neuroseed/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./neuroseed/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in ./neuroseed/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./neuroseed/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->geomstats==2.2) (3.7.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (0.13.1)\n",
      "Requirement already satisfied: jinja2 in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (3.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (0.13.3)\n",
      "Requirement already satisfied: argon2-cffi in ./neuroseed/lib/python3.8/site-packages (from notebook->jupyter->geomstats==2.2) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./neuroseed/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->geomstats==2.2) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./neuroseed/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->geomstats==2.2) (1.15.0)\n",
      "Requirement already satisfied: pycparser in ./neuroseed/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->geomstats==2.2) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./neuroseed/lib/python3.8/site-packages (from jinja2->notebook->jupyter->geomstats==2.2) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (4.30.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./neuroseed/lib/python3.8/site-packages (from matplotlib->geomstats==2.2) (21.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (1.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.5.12)\n",
      "Requirement already satisfied: bleach in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (4.1.0)\n",
      "Requirement already satisfied: testpath in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./neuroseed/lib/python3.8/site-packages (from nbconvert->jupyter->geomstats==2.2) (0.1.2)\n",
      "Requirement already satisfied: webencodings in ./neuroseed/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->geomstats==2.2) (0.5.1)\n",
      "Requirement already satisfied: qtpy in ./neuroseed/lib/python3.8/site-packages (from qtconsole->jupyter->geomstats==2.2) (2.0.1)\n",
      "Requirement already satisfied: asttokens in ./neuroseed/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (2.0.5)\n",
      "Requirement already satisfied: executing in ./neuroseed/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in ./neuroseed/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->geomstats==2.2) (0.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/noga/NeuroSEED/neuroseed/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install geoopt==0.3.1\n",
    "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip3 install geomstats==2.2\n",
    "#!apt install clustalw\n",
    "#pip install biopython\n",
    "#!pip install python-Levenshtein\n",
    "#!pip install Cython\n",
    "#!pip install networkx\n",
    "#!pip install tqdm\n",
    "#!pip install gdown\n",
    "#!cd hierarchical_clustering/relaxed/mst; python setup.py build_ext --inplace; cd ../unionfind; python setup.py build_ext --inplace; cd ..; cd ..; cd ..;\n",
    "os.environ['GEOMSTATS_BACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym4wkXPfc4O3",
    "outputId": "6285cb49-5a92-4fb1-a8c7-f5acf731abf1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from geomstats.geometry.poincare_ball import PoincareBall\n",
    "\n",
    "from edit_distance.train import load_edit_distance_dataset\n",
    "from util.data_handling.data_loader import get_dataloaders\n",
    "from util.ml_and_math.loss_functions import AverageMeter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OSApf0PemhP"
   },
   "source": [
    "### Dataset description\n",
    "\n",
    "As microbiome analysis is one of the most critical applications where the methods presented could be applied, we chose to use a dataset containing a portion of the 16S rRNA gene widely used in the biological literature to analyse microbiome diversity. Qiita (Clemente et al. 2015) contains more than 6M sequences of up to 152 bp that cover the V4 hyper-variable region collected from skin, saliva and faeces samples of uncontacted Amerindians. The full dataset can be found on the [European Nucleotide Archive](https://www.ebi.ac.uk/ena/browser/text-search?query=ERP008799), but, in this notebook, we will only use a subset of a few tens of thousands that have been preprocessed and labelled with pairwise distances. We also provide results on the RT988 dataset (Zheng et al. 2019), another dataset of 16S rRNA that contains slightly longer sequences (up to 465 bp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvVBQf6idzcA",
    "outputId": "4a17696a-322f-4398-8ad5-c202d02d4458"
   },
   "outputs": [],
   "source": [
    "#!gdown --id 1yZTOYrnYdW9qRrwHSO5eRc8rYIPEVtY2 # for edit distance approximation\n",
    "#!gdown --id 1hQSHR-oeuS9bDVE6ABHS0SoI4xk3zPnB # for closest string retrieval\n",
    "#!gdown --id 1ukvUI6gUTbcBZEzTVDpskrX8e6EHqVQg # for hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mH5MrL1hYIL"
   },
   "source": [
    "### Edit distance approximation\n",
    "\n",
    "**Edit distance**  The task of finding the distance or similarity between two strings and the related task of global alignment lies at the foundation of bioinformatics. Due to the resemblance with the biological mutation process, the edit distance and its variants are typically used to measure similarity between sequences. Given two string $s_1$ and $s_2$, their edit distance $ED(s_1, s_2)$ is defined as the minimum number of insertions, deletions or substitutions needed to transform $s_1$ in $s_2$. We always deal with the classical edit distance where the same weight is given to every operation, however, all the approaches developed can be applied to any distance function of choice. \n",
    "\n",
    "**Task and loss function** As represented in Figure 3, the task is to learn an encoding function $f$ such that given any pair of sequences from the domain of interest $s_1$ and $s_2$:\n",
    "\\begin{equation}ED(s_1, s_2) \\approx n \\; d(f(s_1), f(s_2)) \\end{equation}\n",
    "\n",
    "where $n$ is the maximum sequence length and $d$ is a distance function over the vector space. In practice this is enforced in the model by minimising the mean squared error between the actual and the predicted edit distance. To make the results more interpretable and comparable across different datasets, we report results using \\% RMSE defined as:\n",
    "\\begin{equation}\n",
    "\\text{% RMSE}(f, S) = \\frac{100}{n} \\, \\sqrt{L(f, S)} = \\frac{100}{n} \\, \\sqrt{\\sum_{s_1, s_2 \\in S} (ED(s_1, s_2) - n \\; d(f(s_1), f(s_2)))^2}\n",
    "\\end{equation}\n",
    "\n",
    "which can be interpreted as an approximate average error in the distance prediction as a percentage of the size of the sequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0EAvdHOjOoU"
   },
   "source": [
    "In this notebook, we only show the code to run a simple linear layer on the sequence which, in the hyperbolic space, already gives particularly good results. Later we will also report results for more complex models whose implementation can be found in the [NeuroSEED repository](https://github.com/gcorso/NeuroSEED)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EXBg45KBeACe"
   },
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\n",
    "    \"\"\"  Linear model which simply flattens the sequence and applies a linear transformation. \"\"\"\n",
    "\n",
    "    def __init__(self, len_sequence, embedding_size, alphabet_size=4):\n",
    "        super(LinearEncoder, self).__init__()\n",
    "        self.encoder = nn.Linear(in_features=alphabet_size * len_sequence, \n",
    "                                 out_features=embedding_size)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # flatten sequence and apply layer\n",
    "        B = sequence.shape[0]\n",
    "        sequence = sequence.reshape(B, -1)\n",
    "        emb = self.encoder(sequence)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class PairEmbeddingDistance(nn.Module):\n",
    "    \"\"\" Wrapper model for a general encoder, computes pairwise distances and applies projections \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_model, embedding_size, scaling=False):\n",
    "        super(PairEmbeddingDistance, self).__init__()\n",
    "        self.hyperbolic_metric = PoincareBall(embedding_size).metric.dist\n",
    "        self.embedding_model = embedding_model\n",
    "        self.radius = nn.Parameter(torch.Tensor([1e-2]), requires_grad=True)\n",
    "        self.scaling = nn.Parameter(torch.Tensor([1.]), requires_grad=True)\n",
    "\n",
    "    def normalize_embeddings(self, embeddings):\n",
    "        \"\"\" Project embeddings to an hypersphere of a certain radius \"\"\"\n",
    "        min_scale = 1e-7\n",
    "        max_scale = 1 - 1e-3\n",
    "        return F.normalize(embeddings, p=2, dim=1) * self.radius.clamp_min(min_scale).clamp_max(max_scale)\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        \"\"\" Use embedding model and normalization to encode some sequences. \"\"\"\n",
    "        enc_sequence = self.embedding_model(sequence)\n",
    "        enc_sequence = self.normalize_embeddings(enc_sequence)\n",
    "        return enc_sequence\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # flatten couples\n",
    "        (B, _, N, _) = sequence.shape\n",
    "        sequence = sequence.reshape(2 * B, N, -1)\n",
    "\n",
    "        # encode sequences\n",
    "        enc_sequence = self.encode(sequence)\n",
    "\n",
    "        # compute distances\n",
    "        enc_sequence = enc_sequence.reshape(B, 2, -1)\n",
    "        distance = self.hyperbolic_metric(enc_sequence[:, 0], enc_sequence[:, 1])\n",
    "        distance = distance * self.scaling\n",
    "\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDa6aholkv4z"
   },
   "source": [
    "General training and evaluation routines used to train the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0_TS2a5VmQCQ"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss, device):\n",
    "    avg_loss = AverageMeter()\n",
    "    model.train()\n",
    "\n",
    "    for sequences, labels in loader:\n",
    "        # move examples to right device\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        optimizer.zero_grad()\n",
    "        output = model(sequences)\n",
    "\n",
    "        # loss and backpropagation\n",
    "        loss_train = loss(output, labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of average loss\n",
    "        avg_loss.update(loss_train.data.item(), sequences.shape[0])\n",
    "\n",
    "    return avg_loss.avg\n",
    "\n",
    "\n",
    "def test(model, loader, loss, device):\n",
    "    avg_loss = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    for sequences, labels in loader:\n",
    "        # move examples to right device\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "        # forward propagation and loss computation\n",
    "        output = model(sequences)\n",
    "        loss_val = loss(output, labels).data.item()\n",
    "        avg_loss.update(loss_val, sequences.shape[0])\n",
    "\n",
    "    return avg_loss.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49GU1jZAlBTE"
   },
   "source": [
    "The linear model is trained on 7000 sequences (+700 of validation) and tested on 1500 different sequences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test'])\n"
     ]
    }
   ],
   "source": [
    "# create subset of qiita to better understand mechanisms\n",
    "import pickle\n",
    "\n",
    "with open('./datasets/string_subset.pkl', 'rb') as f:\n",
    "        sequences, distances = pickle.load(f)\n",
    "\n",
    "print(distances.keys())\n",
    "slices={'train':200, 'test':100, 'val':100}\n",
    "smaller_distances = {key: distances[key][:slices[key],:slices[key]] for key in distances.keys()}\n",
    "smaller_sequences = {key: sequences[key][:slices[key]] for key in sequences.keys()}\n",
    "\n",
    "pickle.dump((smaller_sequences, smaller_distances),open('./datasets/string_subsubset' + \".pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UC6Qio4WSnSh",
    "outputId": "2ed86477-69a6-4547-8740-1072224973d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 loss_train: 0.186405 loss_val: 0.110037 time: 4.5014s\n",
      "Final results train: loss = 0.166017\n",
      "Final results val: loss = 0.110037\n",
      "Final results test: loss = 0.114581\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 4\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(2021)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(2021)\n",
    "\n",
    "# load data\n",
    "datasets = load_edit_distance_dataset('./datasets/string_subsubset.pkl')\n",
    "loaders = get_dataloaders(datasets, batch_size=128, workers=5)\n",
    "\n",
    "# model, optimizer and loss\n",
    "encoder = LinearEncoder(153, EMBEDDING_SIZE)\n",
    "model = PairEmbeddingDistance(embedding_model=encoder, embedding_size=EMBEDDING_SIZE)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# training\n",
    "for epoch in range(0, 1):\n",
    "    t = time.time()\n",
    "    loss_train = train(model, loaders['train'], optimizer, loss, device)\n",
    "    loss_val = test(model, loaders['val'], loss, device)\n",
    "\n",
    "    # print progress\n",
    "    if epoch % 1 == 0:\n",
    "        print('Epoch: {:02d}'.format(epoch),\n",
    "              'loss_train: {:.6f}'.format(loss_train),\n",
    "              'loss_val: {:.6f}'.format(loss_val),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "      \n",
    "# testing\n",
    "for dset in loaders.keys():\n",
    "    avg_loss = test(model, loaders[dset], loss, device)\n",
    "    print('Final results {}: loss = {:.6f}'.format(dset, avg_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyYzk2BllSP1"
   },
   "source": [
    "Therefore, our linear model after only 50 epochs has a $\\% RMSE \\approx 2.6$ that, as we will see, is significantly better than any data-independent baseline. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural SEED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
